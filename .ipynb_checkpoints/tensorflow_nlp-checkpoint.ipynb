{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6578e17-2b3f-4bda-acd1-8e6cf522582b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0106759-eea4-4972-aca3-9f0f33bc966e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    \"The quick brown fox jumps over the lazy dog.\",\n",
    "    \"She sells seashells by the seashore.\",\n",
    "    \"How much wood would a woodchuck chuck if a woodchuck could chuck wood?\",\n",
    "    \"To be or not to be, that is the question.\",\n",
    "    \"A journey of a thousand miles begins with a single step.\",\n",
    "    \"The early bird catches the worm.\",\n",
    "    \"Actions speak louder than words.\",\n",
    "    \"Beauty is in the eye of the beholder.\",\n",
    "    \"When in Rome, do as the Romans do.\",\n",
    "    \"Every cloud has a silver lining.\"\n",
    "]\n",
    "tokenizer=Tokenizer(num_words=100,oov_token=\"<oov>\")\n",
    "tokenizer.fit_on_texts(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bfeb0b57-375a-48b5-a3a6-50b8a591c54d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<oov>': 1, 'the': 2, 'a': 3, 'wood': 4, 'woodchuck': 5, 'chuck': 6, 'to': 7, 'be': 8, 'is': 9, 'of': 10, 'in': 11, 'do': 12, 'quick': 13, 'brown': 14, 'fox': 15, 'jumps': 16, 'over': 17, 'lazy': 18, 'dog': 19, 'she': 20, 'sells': 21, 'seashells': 22, 'by': 23, 'seashore': 24, 'how': 25, 'much': 26, 'would': 27, 'if': 28, 'could': 29, 'or': 30, 'not': 31, 'that': 32, 'question': 33, 'journey': 34, 'thousand': 35, 'miles': 36, 'begins': 37, 'with': 38, 'single': 39, 'step': 40, 'early': 41, 'bird': 42, 'catches': 43, 'worm': 44, 'actions': 45, 'speak': 46, 'louder': 47, 'than': 48, 'words': 49, 'beauty': 50, 'eye': 51, 'beholder': 52, 'when': 53, 'rome': 54, 'as': 55, 'romans': 56, 'every': 57, 'cloud': 58, 'has': 59, 'silver': 60, 'lining': 61}\n"
     ]
    }
   ],
   "source": [
    "token = tokenizer.word_index\n",
    "print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "26e14463-2e76-4daf-8bbc-054ec4fd4bb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2, 13, 14, 15, 16, 17, 2, 18, 19], [20, 21, 22, 23, 2, 24], [25, 26, 4, 27, 3, 5, 6, 28, 3, 5, 29, 6, 4], [7, 8, 30, 31, 7, 8, 32, 9, 2, 33], [3, 34, 10, 3, 35, 36, 37, 38, 3, 39, 40], [2, 41, 42, 43, 2, 44], [45, 46, 47, 48, 49], [50, 9, 11, 2, 51, 10, 2, 52], [53, 11, 54, 12, 55, 2, 56, 12], [57, 58, 59, 3, 60, 61]]\n"
     ]
    }
   ],
   "source": [
    "sequence = tokenizer.texts_to_sequences(sentences)\n",
    "print(sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c8f96753-bc20-491e-b51b-373f9df97d1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2 13 14 15 16 17  2 18 19  0  0  0  0]\n",
      " [20 21 22 23  2 24  0  0  0  0  0  0  0]\n",
      " [25 26  4 27  3  5  6 28  3  5 29  6  4]\n",
      " [ 7  8 30 31  7  8 32  9  2 33  0  0  0]\n",
      " [ 3 34 10  3 35 36 37 38  3 39 40  0  0]\n",
      " [ 2 41 42 43  2 44  0  0  0  0  0  0  0]\n",
      " [45 46 47 48 49  0  0  0  0  0  0  0  0]\n",
      " [50  9 11  2 51 10  2 52  0  0  0  0  0]\n",
      " [53 11 54 12 55  2 56 12  0  0  0  0  0]\n",
      " [57 58 59  3 60 61  0  0  0  0  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "padding = pad_sequences(sequence,padding=\"post\")\n",
    "#padding = pad_sequences(sequence,padding=\"post\",max_len)\n",
    "print(padding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48df054f-3772-4253-923c-47866ca15e30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
